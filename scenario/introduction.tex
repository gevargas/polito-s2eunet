The emergence of new architectures like the cloud opens new opportunities to data processing. 
The possibility of having unlimited access to cloud resources and the ``pay as U go'' model make it possible to change the hypothesis for processing big  data collections. 
Instead of designing processes and algorithms taking into consideration  limitations on resources availability, the cloud sets the focus on the economic cost implied of using resources and producing results by parallelizing their use owhile delivering data under subscription oriented cost models.
 
Integrating and processing heterogeneous data collections, calls for efficient methods for correlating, associating, filtering them taking into consideration their ``structural'' characteristics (due to the different data models) but also their quality, e.g., trust, freshness, provenance, partial or total consistency. 


Our work addresses big data collections .  

Therefore this paper presents an approach ...

Accordingly, the remainder of this paper is organized as follows. Section \ref{sec:relWork} presents related works that ... Section \ref{sec:incremental} gives an overview of our approach for .... 
%Section \ref{sec:incremental} introduces on demand and incremental data integration strategies. 
%Section \ref{sec:useCase} presents a use case for illustrating the interest and use of our approach. 
Finally \ref{sec:conclusions} concludes the papers and discusses future work.